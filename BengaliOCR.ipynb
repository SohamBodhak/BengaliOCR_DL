{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7dac9e-e856-4c65-a79c-a6671354e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 48, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1728, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=84, bias=True)\n",
      ")\n",
      "Epoch 1/20: Train Loss: 1.6615, Train Acc: 54.74%, Val Loss: 0.7640, Val Acc: 78.07%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 2/20: Train Loss: 0.9186, Train Acc: 73.65%, Val Loss: 0.6186, Val Acc: 82.13%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 3/20: Train Loss: 0.7862, Train Acc: 77.20%, Val Loss: 0.5590, Val Acc: 84.42%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 4/20: Train Loss: 0.7126, Train Acc: 79.40%, Val Loss: 0.5403, Val Acc: 84.56%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 5/20: Train Loss: 0.6733, Train Acc: 80.42%, Val Loss: 0.5163, Val Acc: 85.16%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 6/20: Train Loss: 0.6330, Train Acc: 81.53%, Val Loss: 0.4910, Val Acc: 86.12%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 7/20: Train Loss: 0.6077, Train Acc: 82.35%, Val Loss: 0.5010, Val Acc: 85.79%\n",
      "Epoch 8/20: Train Loss: 0.5859, Train Acc: 82.93%, Val Loss: 0.4906, Val Acc: 86.22%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 9/20: Train Loss: 0.5715, Train Acc: 83.26%, Val Loss: 0.4537, Val Acc: 87.23%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 10/20: Train Loss: 0.5538, Train Acc: 83.83%, Val Loss: 0.4724, Val Acc: 87.04%\n",
      "Epoch 11/20: Train Loss: 0.5408, Train Acc: 84.23%, Val Loss: 0.4484, Val Acc: 87.32%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 12/20: Train Loss: 0.5320, Train Acc: 84.39%, Val Loss: 0.4337, Val Acc: 87.91%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 13/20: Train Loss: 0.5178, Train Acc: 84.86%, Val Loss: 0.4319, Val Acc: 87.94%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 14/20: Train Loss: 0.5088, Train Acc: 85.10%, Val Loss: 0.4240, Val Acc: 88.20%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 15/20: Train Loss: 0.5033, Train Acc: 85.31%, Val Loss: 0.4303, Val Acc: 88.03%\n",
      "Epoch 16/20: Train Loss: 0.4960, Train Acc: 85.35%, Val Loss: 0.4345, Val Acc: 88.00%\n",
      "Epoch 17/20: Train Loss: 0.4895, Train Acc: 85.56%, Val Loss: 0.4209, Val Acc: 88.37%\n",
      "Model saved to models/lenet5.pth\n",
      "Epoch 18/20: Train Loss: 0.4843, Train Acc: 85.69%, Val Loss: 0.4227, Val Acc: 88.31%\n",
      "Epoch 19/20: Train Loss: 0.4799, Train Acc: 85.98%, Val Loss: 0.4225, Val Acc: 88.30%\n",
      "Epoch 20/20: Train Loss: 0.4773, Train Acc: 86.02%, Val Loss: 0.4315, Val Acc: 88.17%\n",
      "Final Validation Accuracy: 88.37%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from uuid import uuid4\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 32\n",
    "NO_OF_CLASSES = 84\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset\n",
    "class BengaliDigitDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PIL Image for transforms\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Data Loading\n",
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_name in os.listdir(path):\n",
    "        label_path = os.path.join(path, label_name)\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_name in os.listdir(label_path):\n",
    "                if img_name.endswith('.png') and not img_name.startswith('.'):\n",
    "                    img_path = os.path.join(label_path, img_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    images.append(img)\n",
    "                    labels.append(label_name)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "# import zipfile\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "\n",
    "# def read_images_from_zip(zip_path):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as archive:\n",
    "#         for file in archive.namelist():\n",
    "#             if file.endswith('.png') and not file.startswith('__MACOSX') and not os.path.basename(file).startswith('.'):\n",
    "#                 label_name = os.path.basename(os.path.dirname(file))\n",
    "#                 with archive.open(file) as img_file:\n",
    "#                     img = Image.open(BytesIO(img_file.read())).convert('L')  # Grayscale\n",
    "#                     img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "#                     img = np.array(img)\n",
    "#                     images.append(img)\n",
    "#                     labels.append(label_name)\n",
    "    \n",
    "#     images = np.array(images)\n",
    "#     labels = np.array(labels)\n",
    "#     return images, labels\n",
    "\n",
    "\n",
    "# LeNet5 Model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 48, kernel_size=5, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(48 * 6 * 6, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Save Model\n",
    "def save_model(model, path=\"models/lenet5.pth\"):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'num_classes': NO_OF_CLASSES\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Load Model\n",
    "def load_model(path=\"models/lenet5.pth\"):\n",
    "    checkpoint = torch.load(path, map_location=DEVICE)\n",
    "    model = LeNet5(checkpoint['num_classes'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / train_total\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / val_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            save_model(model)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Plot Training History\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Val Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history_lenet.png')\n",
    "    plt.close()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Data Transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    data_path = \"Images\"  # Adjust this to your dataset path\n",
    "    images, labels = read_images(data_path)\n",
    "    # images, labels = read_images_from_zip(\"/content/BanglaLekha-Isolated.zip\")\n",
    "\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    \n",
    "    # Split data\n",
    "    train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = BengaliDigitDataset(train_imgs, train_labels, transform=train_transform)\n",
    "    val_dataset = BengaliDigitDataset(val_imgs, val_labels, transform=val_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model, criterion, optimizer\n",
    "    model = LeNet5(NO_OF_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(model)\n",
    "    \n",
    "    # Train model\n",
    "    history = train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS, DEVICE)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_history(history)\n",
    "    \n",
    "    # Visualize a sample\n",
    "    sample_idx = 0\n",
    "    sample_img = val_imgs[sample_idx]\n",
    "    sample_label = val_labels[sample_idx]\n",
    "    \n",
    "    plt.imshow(sample_img, cmap='gray')\n",
    "    plt.title(f'Label: {le.inverse_transform([sample_label])[0]}')\n",
    "    plt.savefig('sample_digit_lenet.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model = load_model()\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Final Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12604ad-287d-4f29-98fa-09b98bd7e2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "330e8828-07f8-4f7f-b08f-98330ac11d84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592491a-3a3c-41c8-af91-d8665524e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971cc3b6-38fb-488c-80ca-ba48e037987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=84, bias=True)\n",
      ")\n",
      "Epoch 1/20: Train Loss: 0.8083, Train Acc: 77.69%, Val Loss: 0.4011, Val Acc: 88.88%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 2/20: Train Loss: 0.4055, Train Acc: 88.51%, Val Loss: 0.3670, Val Acc: 89.77%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 3/20: Train Loss: 0.3461, Train Acc: 90.05%, Val Loss: 0.2791, Val Acc: 92.35%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 4/20: Train Loss: 0.3109, Train Acc: 91.11%, Val Loss: 0.2758, Val Acc: 92.58%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 5/20: Train Loss: 0.2808, Train Acc: 91.93%, Val Loss: 0.2541, Val Acc: 93.21%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 6/20: Train Loss: 0.2616, Train Acc: 92.43%, Val Loss: 0.2524, Val Acc: 93.39%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 7/20: Train Loss: 0.2427, Train Acc: 92.92%, Val Loss: 0.2332, Val Acc: 93.64%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 8/20: Train Loss: 0.2265, Train Acc: 93.43%, Val Loss: 0.2299, Val Acc: 93.89%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 9/20: Train Loss: 0.2130, Train Acc: 93.71%, Val Loss: 0.2324, Val Acc: 93.75%\n",
      "Epoch 10/20: Train Loss: 0.2001, Train Acc: 94.09%, Val Loss: 0.2266, Val Acc: 94.00%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 11/20: Train Loss: 0.1894, Train Acc: 94.34%, Val Loss: 0.2303, Val Acc: 94.05%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 12/20: Train Loss: 0.1793, Train Acc: 94.60%, Val Loss: 0.2261, Val Acc: 94.10%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 13/20: Train Loss: 0.1674, Train Acc: 94.85%, Val Loss: 0.2465, Val Acc: 93.61%\n",
      "Epoch 14/20: Train Loss: 0.1592, Train Acc: 95.14%, Val Loss: 0.2255, Val Acc: 94.33%\n",
      "Model saved to models/resnet18.pth\n",
      "Epoch 15/20: Train Loss: 0.1513, Train Acc: 95.30%, Val Loss: 0.2360, Val Acc: 94.05%\n",
      "Epoch 16/20: Train Loss: 0.1432, Train Acc: 95.54%, Val Loss: 0.2416, Val Acc: 94.06%\n",
      "Epoch 17/20: Train Loss: 0.1359, Train Acc: 95.78%, Val Loss: 0.5781, Val Acc: 86.29%\n",
      "Epoch 18/20: Train Loss: 0.1293, Train Acc: 95.98%, Val Loss: 0.2383, Val Acc: 94.21%\n",
      "Epoch 19/20: Train Loss: 0.1219, Train Acc: 96.13%, Val Loss: 0.2455, Val Acc: 94.12%\n",
      "Epoch 20/20: Train Loss: 0.1169, Train Acc: 96.34%, Val Loss: 0.2513, Val Acc: 94.24%\n",
      "Final Validation Accuracy: 94.33%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 32\n",
    "NO_OF_CLASSES = 84\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset\n",
    "class BengaliDigitDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Data Loading\n",
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_name in os.listdir(path):\n",
    "        label_path = os.path.join(path, label_name)\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_name in os.listdir(label_path):\n",
    "                if img_name.endswith('.png') and not img_name.startswith('.'):\n",
    "                    img_path = os.path.join(label_path, img_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    images.append(img)\n",
    "                    labels.append(label_name)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "# Residual Block for ResNet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet-18 Model\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        \n",
    "        # Global average pooling and FC layer\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Save Model\n",
    "def save_model(model, path=\"models/resnet18.pth\"):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'num_classes': NO_OF_CLASSES\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Load Model\n",
    "def load_model(path=\"models/resnet18.pth\"):\n",
    "    checkpoint = torch.load(path, map_location=DEVICE)\n",
    "    model = ResNet18(checkpoint['num_classes'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / train_total\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / val_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            save_model(model)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Plot Training History\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Val Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history_resnet.png')\n",
    "    plt.close()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Data Transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    data_path = \"Images\"  # Adjust this to your dataset path\n",
    "    images, labels = read_images(data_path)\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    \n",
    "    # Split data\n",
    "    train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = BengaliDigitDataset(train_imgs, train_labels, transform=train_transform)\n",
    "    val_dataset = BengaliDigitDataset(val_imgs, val_labels, transform=val_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model, criterion, optimizer\n",
    "    model = ResNet18(NO_OF_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(model)\n",
    "    \n",
    "    # Train model\n",
    "    history = train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS, DEVICE)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_history(history)\n",
    "    \n",
    "    # Visualize a sample\n",
    "    sample_idx = 0\n",
    "    sample_img = val_imgs[sample_idx]\n",
    "    sample_label = val_labels[sample_idx]\n",
    "    \n",
    "    plt.imshow(sample_img, cmap='gray')\n",
    "    plt.title(f'Label: {le.inverse_transform([sample_label])[0]}')\n",
    "    plt.savefig('sample_digit_resnet.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model = load_model()\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Final Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c481a30-34f5-4ab9-9efb-92d6992ab44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
